{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theabdulbasitt/transformer-model-from-scratch/blob/main/Assig_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMrwDI5t2ew9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0ihuIp4Ygw8"
      },
      "source": [
        "# **Designing the Transformer-Based LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBwjvyj-7X1k"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # Create a long enough 'pe' matrix\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        # Compute the positional encodings once in log space.\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, seq_len, d_model]\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "# Multi-Head Attention Mechanism\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "        self.d_k = d_model // num_heads  # Dimension of each head\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Linear layers for Q, K, V\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Output linear layer\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.scale = math.sqrt(self.d_k)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Linear projection and split into heads\n",
        "        Q = self.w_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)  # [B, H, L, Dk]\n",
        "        K = self.w_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.w_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale  # [B, H, L, L]\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)  # [B, H, L, Dk]\n",
        "\n",
        "        # Concatenate heads\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)  # [B, L, D]\n",
        "\n",
        "        # Final linear layer\n",
        "        output = self.fc(context)\n",
        "        return output\n",
        "\n",
        "# Position-wise Feed-Forward Network\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply two linear transformations with ReLU activation in between\n",
        "        return self.linear2(self.dropout(torch.relu(self.linear1(x))))\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff=2048):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, src, src_mask=None):\n",
        "        # Self-attention with residual connection and layer normalization\n",
        "        src2 = self.norm1(src)\n",
        "        attn_output = self.self_attn(src2, src2, src2, src_mask)\n",
        "        src = src + self.dropout(attn_output)\n",
        "\n",
        "        # Feed-forward network with residual connection and layer normalization\n",
        "        src2 = self.norm2(src)\n",
        "        ffn_output = self.ffn(src2)\n",
        "        src = src + self.dropout(ffn_output)\n",
        "        return src\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff=2048):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
        "        # Masked self-attention with residual connection and layer normalization\n",
        "        tgt2 = self.norm1(tgt)\n",
        "        attn_output = self.self_attn(tgt2, tgt2, tgt2, tgt_mask)\n",
        "        tgt = tgt + self.dropout(attn_output)\n",
        "\n",
        "        # Encoder-decoder attention with residual connection and layer normalization\n",
        "        tgt2 = self.norm2(tgt)\n",
        "        attn_output = self.enc_dec_attn(tgt2, memory, memory, memory_mask)\n",
        "        tgt = tgt + self.dropout(attn_output)\n",
        "\n",
        "        # Feed-forward network with residual connection and layer normalization\n",
        "        tgt2 = self.norm3(tgt)\n",
        "        ffn_output = self.ffn(tgt2)\n",
        "        tgt = tgt + self.dropout(ffn_output)\n",
        "        return tgt\n",
        "\n",
        "# Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff=2048, max_len=5000):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(d_model, num_heads, d_ff)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, src, src_mask=None):\n",
        "        # Embed and add positional encoding\n",
        "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoding(src)\n",
        "        src = self.dropout(src)\n",
        "\n",
        "        # Pass through encoder layers\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        return src\n",
        "\n",
        "# Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff=2048, max_len=5000):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model, num_heads, d_ff)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
        "        # Embed and add positional encoding\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
        "        tgt = self.pos_encoding(tgt)\n",
        "        tgt = self.dropout(tgt)\n",
        "\n",
        "        # Pass through decoder layers\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(tgt, memory, tgt_mask, memory_mask)\n",
        "\n",
        "        # Final linear layer to generate predictions\n",
        "        output = self.fc_out(tgt)\n",
        "        return output\n",
        "\n",
        "# Full Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512,\n",
        "                 num_layers=6, num_heads=8, d_ff=2048, max_len=5000):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, num_layers, num_heads, d_ff, max_len)\n",
        "        self.decoder = Decoder(tgt_vocab_size, d_model, num_layers, num_heads, d_ff, max_len)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        # Create a mask for padding tokens in the source sequences\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Shape: [B, 1, 1, L_src]\n",
        "        return src_mask\n",
        "\n",
        "    def make_tgt_mask(self, tgt):\n",
        "        # Create a mask for padding tokens and future tokens in the target sequences\n",
        "        tgt_pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)  # Shape: [B, 1, 1, L_tgt]\n",
        "        tgt_len = tgt.size(1)\n",
        "        tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()  # Shape: [L_tgt, L_tgt]\n",
        "        tgt_mask = tgt_pad_mask & tgt_sub_mask  # Combine masks\n",
        "        return tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        tgt_mask = self.make_tgt_mask(tgt)\n",
        "\n",
        "        memory = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, memory, tgt_mask, src_mask)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9_7g-cbZIg4"
      },
      "source": [
        "# **Data Loading and Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfUncqWE7exY",
        "outputId": "8f07d911-f770-4c27-b918-0ebdfa7a1a05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source Vocabulary Size: 3798\n",
            "Target Vocabulary Size: 1511\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/samsum-test.csv')\n",
        "df = df[['dialogue', 'summary']]\n",
        "\n",
        "# Clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "df['dialogue'] = df['dialogue'].apply(clean_text)\n",
        "df['summary'] = df['summary'].apply(clean_text)\n",
        "\n",
        "# Tokenization\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize(text):\n",
        "    return [token.text.lower() for token in nlp.tokenizer(text)]\n",
        "\n",
        "# Vocabulary class\n",
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold):\n",
        "        self.freq_threshold = freq_threshold\n",
        "        self.itos = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
        "        self.stoi = {v: k for k, v in self.itos.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def build_vocabulary(self, sentences):\n",
        "        frequencies = Counter()\n",
        "        idx = 4  # Starting index for new tokens\n",
        "\n",
        "        for sentence in sentences:\n",
        "            tokens = tokenize(sentence)\n",
        "            frequencies.update(tokens)\n",
        "\n",
        "        # Add tokens to vocabulary if they meet the frequency threshold\n",
        "        for word, freq in frequencies.items():\n",
        "            if freq >= self.freq_threshold:\n",
        "                self.stoi[word] = idx\n",
        "                self.itos[idx] = word\n",
        "                idx += 1\n",
        "\n",
        "def numericalize(text, vocab):\n",
        "    tokenized_text = tokenize(text)\n",
        "    return [\n",
        "        vocab.stoi.get(token, vocab.stoi['<UNK>'])\n",
        "        for token in tokenized_text\n",
        "    ]\n",
        "\n",
        "# Build vocabularies\n",
        "freq_threshold = 2\n",
        "src_vocab = Vocabulary(freq_threshold)\n",
        "tgt_vocab = Vocabulary(freq_threshold)\n",
        "\n",
        "src_vocab.build_vocabulary(df['dialogue'].tolist())\n",
        "tgt_vocab.build_vocabulary(df['summary'].tolist())\n",
        "\n",
        "print(f\"Source Vocabulary Size: {len(src_vocab)}\")\n",
        "print(f\"Target Vocabulary Size: {len(tgt_vocab)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYDFccb8ZTKp"
      },
      "source": [
        "# **Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCyBp1T67nIy",
        "outputId": "b7557c79-c5f7-4f6f-f784-65411413abcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 737\n",
            "Validation samples: 82\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dataset class\n",
        "class SamSumDataset(Dataset):\n",
        "    def __init__(self, df, src_vocab, tgt_vocab, max_src_len=100, max_tgt_len=50):\n",
        "        self.df = df\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.max_src_len = max_src_len\n",
        "        self.max_tgt_len = max_tgt_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text = self.df.iloc[idx]['dialogue']\n",
        "        tgt_text = self.df.iloc[idx]['summary']\n",
        "\n",
        "        # Numericalize\n",
        "        src_seq = numericalize(src_text, self.src_vocab)\n",
        "        tgt_seq = numericalize(tgt_text, self.tgt_vocab)\n",
        "\n",
        "        # Add <SOS> and <EOS> tokens to target sequence\n",
        "        tgt_seq = [self.tgt_vocab.stoi['<SOS>']] + tgt_seq + [self.tgt_vocab.stoi['<EOS>']]\n",
        "\n",
        "        # Truncate sequences to max lengths\n",
        "        src_seq = src_seq[:self.max_src_len]\n",
        "        tgt_seq = tgt_seq[:self.max_tgt_len]\n",
        "\n",
        "        return torch.tensor(src_seq), torch.tensor(tgt_seq)\n",
        "\n",
        "# Collate function\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    # Pad sequences\n",
        "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=src_vocab.stoi['<PAD>'], batch_first=True)\n",
        "    tgt_batch = torch.nn.utils.rnn.pad_sequence(tgt_batch, padding_value=tgt_vocab.stoi['<PAD>'], batch_first=True)\n",
        "\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# Split the DataFrame into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "train_dataset = SamSumDataset(train_df, src_vocab, tgt_vocab, max_src_len=100, max_tgt_len=50)\n",
        "val_dataset = SamSumDataset(val_df, src_vocab, tgt_vocab, max_src_len=100, max_tgt_len=50)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32  # Adjust based on your computational resources\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBFa1f0xZeEt"
      },
      "source": [
        "# **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze730uIF70SM",
        "outputId": "5f012982-03b3-47d6-e43d-5ef13c649f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] completed in 334.01s\n",
            "Average Training Loss: 60.2694, Validation Loss: 54.4367\n",
            "Model saved.\n",
            "Epoch [2/3] completed in 330.25s\n",
            "Average Training Loss: 59.9649, Validation Loss: 54.4366\n",
            "Model saved.\n",
            "Epoch [3/3] completed in 330.66s\n",
            "Average Training Loss: 59.8423, Validation Loss: 54.4363\n",
            "Model saved.\n",
            "Training completed.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize model\n",
        "src_vocab_size = len(src_vocab)\n",
        "tgt_vocab_size = len(tgt_vocab)\n",
        "model = Transformer(\n",
        "    src_vocab_size=src_vocab_size,\n",
        "    tgt_vocab_size=tgt_vocab_size,\n",
        "    d_model=512,\n",
        "    num_layers=6,\n",
        "    num_heads=8,\n",
        "    d_ff=2048,\n",
        "    max_len=5000\n",
        ").to(device)\n",
        "\n",
        "# Initialize optimizer and scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Custom learning rate scheduler with warm-up\n",
        "class CustomSchedule(optim.lr_scheduler.LambdaLR):\n",
        "    def __init__(self, optimizer, d_model, warmup_steps=4000, last_epoch=-1):\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "        super(CustomSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
        "\n",
        "    def lr_lambda(self, step):\n",
        "        step = max(step, 1)\n",
        "        return (self.d_model ** -0.5) * min(step ** -0.5, step * (self.warmup_steps ** -1.5))\n",
        "\n",
        "scheduler = CustomSchedule(optimizer, d_model=512, warmup_steps=4000)\n",
        "\n",
        "# Initialize loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab.stoi['<PAD>'])\n",
        "\n",
        "# Initialize EarlyStopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How many epochs to wait after last time validation loss improved.\n",
        "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            return False\n",
        "\n",
        "        elif val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            return False\n",
        "\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "            return self.early_stop\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "# Initialize TensorBoard writer\n",
        "writer = SummaryWriter('runs/transformer_experiment')\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (src_batch, tgt_batch) in enumerate(train_loader):\n",
        "        src_batch = src_batch.to(device)\n",
        "        tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "        # Prepare target sequences\n",
        "        tgt_input = tgt_batch[:, :-1]\n",
        "        tgt_output = tgt_batch[:, 1:].contiguous().view(-1)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src_batch, tgt_input)\n",
        "        output = output.view(-1, output.size(-1))\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(output, tgt_output)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, tgt_batch in val_loader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "            tgt_input = tgt_batch[:, :-1]\n",
        "            tgt_output = tgt_batch[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            output = model(src_batch, tgt_input)\n",
        "            output = output.view(-1, output.size(-1))\n",
        "\n",
        "            loss = criterion(output, tgt_output)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # Log losses to TensorBoard\n",
        "    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
        "    writer.add_scalar('Loss/validation', avg_val_loss, epoch)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] completed in {elapsed_time:.2f}s')\n",
        "    print(f'Average Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if early_stopping(avg_val_loss):\n",
        "        print(\"Early stopping triggered. Stopping training.\")\n",
        "        break\n",
        "\n",
        "    # Save the model if validation loss has decreased\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), 'best_transformer_model.pth')\n",
        "        print(\"Model saved.\")\n",
        "\n",
        "# Close TensorBoard writer\n",
        "writer.close()\n",
        "\n",
        "print(\"Training completed.\")\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Training Loss', marker='o')\n",
        "plt.plot(val_losses, label='Validation Loss', marker='o')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HXB33sAZo5W"
      },
      "source": [
        "# **Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ievuLG6tJgQY",
        "outputId": "f6eba085-a721-43c6-fb87-610d2830c170"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-60b9e53ecda6>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
            "100%|██████████| 82/82 [22:03<00:00, 16.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Custom Model ROUGE Scores:\n",
            "ROUGE-1:\n",
            "  Precision: 0.0155\n",
            "  Recall:    0.0379\n",
            "  F1 Score:  0.0205\n",
            "ROUGE-2:\n",
            "  Precision: 0.0000\n",
            "  Recall:    0.0000\n",
            "  F1 Score:  0.0000\n",
            "ROUGE-L:\n",
            "  Precision: 0.0140\n",
            "  Recall:    0.0345\n",
            "  F1 Score:  0.0186\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer, scoring\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Inference function\n",
        "def generate_summary(model, src_sentence, src_vocab, tgt_vocab, max_len=50):\n",
        "    model.eval()\n",
        "    src_seq = numericalize(src_sentence, src_vocab)\n",
        "    src_seq = torch.tensor(src_seq).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_seq)\n",
        "\n",
        "    # Encode the source sequence\n",
        "    memory = model.encoder(src_seq, src_mask)\n",
        "\n",
        "    # Initialize the decoder input with <SOS>\n",
        "    ys = torch.ones(1, 1).fill_(tgt_vocab.stoi['<SOS>']).type(torch.long).to(device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        tgt_mask = model.make_tgt_mask(ys)\n",
        "        out = model.decoder(ys, memory, tgt_mask, src_mask)\n",
        "        out = out[:, -1, :]  # Get the last time step\n",
        "        prob = F.softmax(out, dim=-1)\n",
        "        next_word = torch.argmax(prob, dim=1).item()\n",
        "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src_seq).fill_(next_word)], dim=1)\n",
        "        if next_word == tgt_vocab.stoi['<EOS>']:\n",
        "            break\n",
        "\n",
        "    # Convert indices to words\n",
        "    predicted_tokens = [tgt_vocab.itos[idx] for idx in ys.squeeze().tolist()]\n",
        "    # Remove <SOS> and tokens after <EOS>\n",
        "    if '<EOS>' in predicted_tokens:\n",
        "        eos_index = predicted_tokens.index('<EOS>')\n",
        "        predicted_tokens = predicted_tokens[1:eos_index]\n",
        "    else:\n",
        "        predicted_tokens = predicted_tokens[1:]\n",
        "    return ' '.join(predicted_tokens)\n",
        "\n",
        "# Generate summaries and collect references\n",
        "references = []\n",
        "hypotheses = []\n",
        "\n",
        "for idx in tqdm(range(len(val_df))):\n",
        "    src_text = val_df.iloc[idx]['dialogue']\n",
        "    tgt_text = val_df.iloc[idx]['summary']\n",
        "\n",
        "    # Generate summary\n",
        "    generated_summary = generate_summary(model, src_text, src_vocab, tgt_vocab)\n",
        "\n",
        "    # Append to lists\n",
        "    references.append(tgt_text)\n",
        "    hypotheses.append(generated_summary)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "aggregator = scoring.BootstrapAggregator()\n",
        "\n",
        "for ref, hyp in zip(references, hypotheses):\n",
        "    scores = scorer.score(ref, hyp)\n",
        "    aggregator.add_scores(scores)\n",
        "\n",
        "result = aggregator.aggregate()\n",
        "\n",
        "# Print ROUGE scores\n",
        "print(\"\\nCustom Model ROUGE Scores:\")\n",
        "print(\"ROUGE-1:\")\n",
        "print(f\"  Precision: {result['rouge1'].mid.precision:.4f}\")\n",
        "print(f\"  Recall:    {result['rouge1'].mid.recall:.4f}\")\n",
        "print(f\"  F1 Score:  {result['rouge1'].mid.fmeasure:.4f}\")\n",
        "\n",
        "print(\"ROUGE-2:\")\n",
        "print(f\"  Precision: {result['rouge2'].mid.precision:.4f}\")\n",
        "print(f\"  Recall:    {result['rouge2'].mid.recall:.4f}\")\n",
        "print(f\"  F1 Score:  {result['rouge2'].mid.fmeasure:.4f}\")\n",
        "\n",
        "print(\"ROUGE-L:\")\n",
        "print(f\"  Precision: {result['rougeL'].mid.precision:.4f}\")\n",
        "print(f\"  Recall:    {result['rougeL'].mid.recall:.4f}\")\n",
        "print(f\"  F1 Score:  {result['rougeL'].mid.fmeasure:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COXXf6oyZ8Bo"
      },
      "source": [
        "# **Sample Text and Summarization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3drRY-rAPEW_",
        "outputId": "ac4d1a54-e72d-4372-dcde-ff1cdacb4c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Input Dialogue:\n",
            "Olafur: are we doing anything for New Year's Eve? Nathalie: I was thinking about something classy, like opera or sth like that Zoe: how much does it cost? Olafur: opera is not for me Nathalie: so what do you propose? Nathalie: it's 100$ Olafur: I was thinking about partying somewhere Nathalie: partying sounds fun, as long as it will be classy Zoe: <file_link> Zoe: Breakfast at Tiffany's party sounds classy Olafur: <file_link> Olafur: is it classy enough? Nathalie: :O Nathalie: this club is AMAZING Zoe: whoa Nathalie: we'll going to Soho then Olafur: we just need to hurry up and buy some tickets soon Zoe: sure\n",
            "\n",
            "Reference Summary:\n",
            "Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\n",
            "\n",
            "Generated Summary:\n",
            "left olivia year marcel leave think daniel marty phil supposed terry allergic book bottle delivery mom platform selling close graham special post but what elena likes pizza winnie join gym fight had ticket helen samuel jake soon patti outside course twice logan close graham special post but what elena 6th\n",
            "\n",
            "Comparison:\n",
            "Reference Summary:\n",
            "Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\n",
            "\n",
            "Generated Summary:\n",
            "left olivia year marcel leave think daniel marty phil supposed terry allergic book bottle delivery mom platform selling close graham special post but what elena likes pizza winnie join gym fight had ticket helen samuel jake soon patti outside course twice logan close graham special post but what elena 6th\n"
          ]
        }
      ],
      "source": [
        "# Select a sample index from the validation set\n",
        "sample_index = 0  # Change this index to test different samples\n",
        "\n",
        "# Extract the sample dialogue and reference summary\n",
        "sample_dialogue = val_df.iloc[sample_index]['dialogue']\n",
        "reference_summary = val_df.iloc[sample_index]['summary']\n",
        "\n",
        "print(\"\\nSample Input Dialogue:\")\n",
        "print(sample_dialogue)\n",
        "\n",
        "print(\"\\nReference Summary:\")\n",
        "print(reference_summary)\n",
        "\n",
        "# Generate the predicted summary\n",
        "generated_summary = generate_summary(model, sample_dialogue, src_vocab, tgt_vocab)\n",
        "\n",
        "print(\"\\nGenerated Summary:\")\n",
        "print(generated_summary)\n",
        "\n",
        "# Compare and analyze the summaries\n",
        "print(\"\\nComparison:\")\n",
        "print(\"Reference Summary:\")\n",
        "print(reference_summary)\n",
        "\n",
        "print(\"\\nGenerated Summary:\")\n",
        "print(generated_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fUvui_jPJPl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}